<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Alexander Nemecek</title>
    <link rel="stylesheet" href="css/main.css">
    <script src="js/nav.js"></script>
    <script src="js/footer.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <main>
        <h1 class="page-title">Publications</h1>
        
        <div class="content-section">
            <ul class="publication-list">
                <li class="publication-entry">
                    <p class="pub-number">[1]</p>
                    <p class="pub-title">Optimal Watermark Generation under Type I and Type II Errors.</p>
                    <p class="pub-authors">Hengzhi He, Shirong Xu, <strong>Alexander Nemecek</strong>, Jiping Li, Erman Ayday, Guang Cheng.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2512.05333, 2025.</p>
                    <p class="pub-abstract">We formulate watermarking as a statistical hypothesis testing problem between a null distribution and its watermarked counterpart. Under explicit constraints on false-positive and false-negative rates, we derive a tight lower bound on the achievable fidelity loss and characterize the optimal watermarked distribution that attains this bound.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2512.05333" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex6')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[2]</p>
                    <p class="pub-title">The Feasibility of Topic-Based Watermarking on Academic Peer Reviews.</p>
                    <p class="pub-authors"><strong>Alexander Nemecek</strong>, Yuzhou Jiang, Erman Ayday.</p>
                    <p class="pub-venue">Proceedings of the 14th International Joint Conference on Natural Language Processing and the 4th Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics, 2025.</p>
                    <p class="pub-abstract">This paper evaluates topic-based watermarking (TBW) for detecting LLM-generated academic peer reviews, finding that it preserves review quality while maintaining strong detection accuracy even under paraphrasing attacks. The study shows TBW can reliably identify machine-generated reviews across different model configurations.</p>
                    <p class="pub-links">
                        <a href="https://aclanthology.org/2025.findings-ijcnlp.36.pdf" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex4')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[3]</p>
                    <p class="pub-title">Exploring Membership Inference Vulnerabilities in Clinical Large Language Models.</p>
                    <p class="pub-authors"><strong>Alexander Nemecek</strong>, Zebin Yun, Zahra Rahmani, Yaniv Harel, Vipin Chaudhary, Mahmood Sharif, Erman Ayday.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2510.18674, 2025.</p>
                    <p class="pub-abstract">We present an exploratory empirical study on membership inference vulnerabilities in clinical LLMs, focusing on whether adversaries can infer if specific patient records were used during model training. Using the clinical question-answering model Llemr, we evaluate loss-based attacks and a domain-motivated paraphrasing-based perturbation strategy.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2510.18674" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex7')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[4]</p>
                    <p class="pub-title">ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models.</p>
                    <p class="pub-authors">Mina Namazi, <strong>Alexander Nemecek</strong>, Erman Ayday.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2506.20915, 2025.</p>
                    <p class="pub-abstract">This paper introduces ZKPROV, a cryptographic framework that uses zero-knowledge proofs to verify that large language model responses derive from authorized datasets without revealing the dataset contents or model parameters. ZKPROV provides statistical guarantees that a model was trained on specific authenticated data through efficient recursive proof systems.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2506.20915" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex3')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[5]</p>
                    <p class="pub-title">Watermarking Without Standards Is Not AI Governance.</p>
                    <p class="pub-authors"><strong>Alexander Nemecek</strong>, Yuzhou Jiang, Erman Ayday.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2505.23814, 2025.</p>
                    <p class="pub-abstract">This paper argues that current watermarking for AI-generated content lacks the technical robustness and standardization needed for effective governance, often failing basic transformations like paraphrasing. We propose a three-layer framework requiring technical standards, independent audits, and enforceable policies to transform watermarking from symbolic compliance into meaningful accountability.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2505.23814" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex2')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[6]</p>
                    <p class="pub-title">Cluster-Aware Attacks on Graph Watermarks.</p>
                    <p class="pub-authors"><strong>Alexander Nemecek</strong>, Emre Yilmaz, Erman Ayday.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2504.17971, 2025.</p>
                    <p class="pub-abstract">This paper introduces cluster-aware attacks on graph watermarks, where adversaries exploit community structure to strategically add/remove edges. The authors propose a mitigation strategy that distributes watermark nodes across graph communities, improving attribution accuracy under attack.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2504.17971" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex5')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[7]</p>
                    <p class="pub-title">Topic-Based Watermarks for Large Language Models.</p>
                    <p class="pub-authors"><strong>Alexander Nemecek</strong>, Yuzhou Jiang, Erman Ayday.</p>
                    <p class="pub-venue">arXiv preprint arXiv:2404.02138, 2024.</p>
                    <p class="pub-abstract">This paper proposes a topic-based watermarking scheme for large language models that partitions vocabulary into semantically aligned token subsets. We demonstrate that our method achieves comparable text quality to industry systems while providing enhanced robustness against paraphrasing and lexical perturbation attacks.</p>
                    <p class="pub-links">
                        <a href="https://arxiv.org/pdf/2404.02138" target="_blank">PDF</a>
                        <button onclick="showBibtex('bibtex1')">BibTeX</button>
                    </p>
                </li>

                <li class="publication-entry">
                    <p class="pub-number">[8]</p>
                    <p class="pub-title">Can Smaller Expert Modules Enhance RAG Performance?</p>
                    <p class="pub-authors"><strong>Alexander J. Nemecek</strong>, Christopher J. Garasi, Robert G. Abbott.</p>
                    <p class="pub-venue">Sandia National Laboratories, SAND2024-14215C. Chesapeake Large-Scale Analytics Conference (CLSAC), Invited Poster, 2024.</p>
                    <p class="pub-abstract">A study on whether smaller expert modules can improve retrieval-augmented generation (RAG) performance, exploring parameter-efficient fine-tuning methods including LoRA and QLoRA for domain-specific adaptation.</p>
                    <p class="pub-links">
                        <a href="https://www.osti.gov/servlets/purl/2999210" target="_blank">Poster</a>
                        <button onclick="showBibtex('bibtex8')">BibTeX</button>
                    </p>
                </li>
            </ul>
        </div>

        <!-- BibTeX Modal -->
        <div id="bibtexModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h3>BibTeX Citation</h3>
                    <span class="close" onclick="closeBibtex()">&times;</span>
                </div>
                <div class="modal-body">
                    <pre id="bibtexContent"></pre>
                </div>
                <div class="modal-footer">
                    <button class="btn btn-primary" onclick="copyBibtex()">
                        <i class="fas fa-copy"></i> Copy
                    </button>
                </div>
            </div>
        </div>
    </main>
    
    <script src="js/main.js"></script>
</body>
</html>
